{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges(G,a,b,connected_node,edges):\n",
    "    G.add_edge(a,b)\n",
    "    if nx.is_directed_acyclic_graph(G):\n",
    "        edges -= 1\n",
    "        connected_node.append(a)\n",
    "        connected_node.append(b)\n",
    "        connected_node = list(set(connected_node))\n",
    "    else:\n",
    "        G.remove_edge(a,b)\n",
    "    return G,connected_node,edges\n",
    "\n",
    "def random_dag(nodes, edges):\n",
    "    \"\"\"Generate a random Directed Acyclic Graph (DAG) with a given number of nodes and edges.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(nodes):\n",
    "        G.add_node(i)\n",
    "        \n",
    "    connected_node = []\n",
    "    while edges > 0:\n",
    "        a = np.random.randint(0,nodes)\n",
    "        b=a\n",
    "        while b==a:\n",
    "            b = np.random.randint(0,nodes-1)\n",
    "        if a not in G.neighbors(b) and b not in G.neighbors(a):\n",
    "            if a in connected_node and b in connected_node:\n",
    "                if np.random.uniform(0, 1)>0.7:\n",
    "                    G,connected_node,edges = add_edges(G,a,b,connected_node,edges)\n",
    "\n",
    "            else:\n",
    "                if np.random.uniform(0, 1)>0.3:\n",
    "                    G,connected_node,edges = add_edges(G,a,b,connected_node,edges)\n",
    "                \n",
    "    return G\n",
    "\n",
    "def remove_DAG_edges(G,num_edges):\n",
    "    random_edges_index = np.random.choice(len(list(G.edges)), size=num_edges, replace=False)\n",
    "    random_edges_index = sorted(random_edges_index,reverse=True)\n",
    "#     print(random_edges_index)\n",
    "    for i in random_edges_index:\n",
    "        random_edge = list(G.edges)[i]\n",
    "        G.remove_edge(random_edge[0],random_edge[1])\n",
    "    return G\n",
    "\n",
    "def add_DAG_edges(G,num_edges):\n",
    "    edges = num_edges\n",
    "    nodes = len(list(G.nodes))\n",
    "    \n",
    "    components = nx.connected_components(G.to_undirected())\n",
    "    connected_node = list([pred for pred in components][0])\n",
    "    \n",
    "    while edges > 0:\n",
    "        a = np.random.randint(0,nodes)\n",
    "        b=a\n",
    "        while b==a:\n",
    "            b = np.random.randint(0,nodes-1)\n",
    "        if a not in G.neighbors(b) and b not in G.neighbors(a):\n",
    "            G,connected_node,edges = add_edges(G,a,b,connected_node,edges)\n",
    "#             if a in connected_node and b in connected_node:\n",
    "#                 if np.random.uniform(0, 1)>0.7:\n",
    "#                     G,connected_node,edges = add_edges(G,a,b,connected_node,edges)\n",
    "\n",
    "#             else:\n",
    "#                 if np.random.uniform(0, 1)>0.3:\n",
    "#                     G,connected_node,edges = add_edges(G,a,b,connected_node,edges)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameters(G,ratio_dis):\n",
    "    num_cate = 4\n",
    "    p = len(G.nodes)\n",
    "    # sigma = np.random.uniform(1,2,(p,)) \n",
    "    n_con = int(p*(1-ratio_dis))\n",
    "    n_dis = p - n_con\n",
    "    type_node = np.concatenate((np.repeat(0,n_con), np.repeat(1,n_dis)))\n",
    "    type_node = np.random.permutation(type_node)\n",
    "\n",
    "    E_mean_con = np.random.uniform(0, 1,p)\n",
    "    E_var_con = np.random.uniform(0.5, 1,p) # gaussion noise variance for continuous variable\n",
    "\n",
    "    # C to C\n",
    "    theta_cc = np.random.uniform(0.5, 1.5,(p,p)) * np.random.choice([-1, 1], (p,p)) # linear coefficient for continuous variable\n",
    "\n",
    "    # D to D\n",
    "    theta_dd = np.ones((p,p,num_cate,num_cate))\n",
    "    theta_dd *= -1/4\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            theta_dd[i,j] *= abs(theta_cc[i,j])\n",
    "            theta_dd[i,j][np.diag_indices(num_cate)] *= -4\n",
    "            theta_dd[i,j] = np.random.permutation(theta_dd[i,j])\n",
    "\n",
    "    # D to C\n",
    "    theta_dc = [[np.random.permutation([-theta_cc[i,j],-0.5*theta_cc[i,j],0.5*theta_cc[i,j],theta_cc[i,j]]) for j in range(p)] for i in range(p)]\n",
    "    theta_dc = np.array(theta_dc)\n",
    "    \n",
    "    return type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc\n",
    "\n",
    "def simulate_data(G,n,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc):\n",
    "    num_cate = 4\n",
    "    p = len(G.nodes)\n",
    "    X = np.zeros((n,p))\n",
    "\n",
    "    roots = []\n",
    "    child = []\n",
    "    for i in list(G.nodes):\n",
    "        if len(nx.ancestors(G, i)) ==0:\n",
    "            roots.append(i)\n",
    "        else: \n",
    "            child.append(i)\n",
    "\n",
    "    def exp_norm(weight):\n",
    "        return np.exp(weight) / np.sum(np.exp(weight))\n",
    "\n",
    "    for r in roots:\n",
    "        node_idx = np.argwhere(np.array(list(G.nodes))==r)[0][0]\n",
    "        if type_node[node_idx] == 0: # continuous node \n",
    "            X[:,r] = np.random.normal(E_mean_con[r], E_var_con[r],size = n)\n",
    "    #         print(r)\n",
    "        else:  # discrete node\n",
    "            weight = [1/num_cate]*num_cate # + E_var_dis[r,]\n",
    "            dis_counts = np.random.multinomial(1, exp_norm(weight), size=n)\n",
    "            X[:,r] = np.argmax(dis_counts,axis=1)\n",
    "\n",
    "            \n",
    "    while len(roots) < p: \n",
    "        node_list = np.array(list(G.nodes))\n",
    "        dis_nodes = node_list[type_node==1]\n",
    "        con_nodes = node_list[type_node==0]\n",
    "\n",
    "        for c in child:\n",
    "            node_idx = np.argwhere(node_list==c)[0][0]\n",
    "\n",
    "            # continuous child node\n",
    "            if len(np.setdiff1d(list(nx.ancestors(G, c)),roots))==0 and type_node[node_idx] == 0:\n",
    "                parent_idx = [pred for pred in G.predecessors(c)]\n",
    "\n",
    "                parent_idx_dis = np.intersect1d(dis_nodes,parent_idx) # discrete parent node\n",
    "                parent_idx_con = np.intersect1d(parent_idx,con_nodes) # continuous parent node\n",
    "\n",
    "                # continuous par + Gaussian noise\n",
    "                X[:,node_idx] = X[:,parent_idx_con] @ theta_cc[parent_idx_con,node_idx] + np.random.normal(0,E_var_con[node_idx],n)\n",
    "                # discrete par\n",
    "                if len(parent_idx_dis)>0:\n",
    "                    for dis_idx in parent_idx_dis:\n",
    "                        X[:,node_idx] += theta_dc[dis_idx,node_idx].flatten()[X[:,dis_idx].flatten().astype(int)]\n",
    "#                 print(parent_idx,node_idx)\n",
    "                child.remove(c);roots.append(c)\n",
    "\n",
    "            # discrete child node \n",
    "            if len(np.setdiff1d(list(nx.ancestors(G, c)),roots))==0 and type_node[node_idx] == 1:\n",
    "                parent_idx = [pred for pred in G.predecessors(c)]\n",
    "\n",
    "                parent_idx_dis = np.intersect1d(dis_nodes,parent_idx) # discrete parent node\n",
    "                parent_idx_con = np.intersect1d(parent_idx,con_nodes) # continuous parent node\n",
    "\n",
    "\n",
    "                Weight = np.random.uniform(0, 1,(n,num_cate))\n",
    "                if len(parent_idx_con)>0:\n",
    "                    for con_idx in parent_idx_con:\n",
    "                        Weight = X[:,[con_idx]] @ theta_dc[[con_idx],node_idx,] + Weight\n",
    "                if len(parent_idx_dis)>0:\n",
    "                    for dis_idx in parent_idx_dis:\n",
    "                        Weight = theta_dd[dis_idx,node_idx][X[:,dis_idx].astype(int)] + Weight\n",
    "                X[:,node_idx] = np.argmax(Weight,axis=1)\n",
    "\n",
    "\n",
    "#                 print(parent_idx,node_idx)\n",
    "                child.remove(c);roots.append(c)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2DF(X):\n",
    "    df_x = pd.DataFrame(X)\n",
    "    df_x.columns =[''.join(['X',str(i)])  for i in range(X.shape[1])]\n",
    "    return df_x\n",
    "\n",
    "def write_graph(G,filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('Graph Nodes:')\n",
    "        my_list = list(G.nodes)\n",
    "        my_list = [''.join(map(str, ['X',i])) for i in my_list]\n",
    "        my_string = ';'.join(map(str, my_list))\n",
    "        f.writelines('\\n')\n",
    "        f.write(my_string)\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('\\n')\n",
    "        f.write('Graph Edges:')\n",
    "        edge_list = list(G.edges)\n",
    "        for i in range(len(edge_list)):\n",
    "            f.writelines('\\n')\n",
    "            f.write(''.join(map(str, [i+1,\".\", ' X', edge_list[i][0],' --> X', edge_list[i][1] ])))\n",
    "        f.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parameter(G,filename,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc):\n",
    "    with open(filename, 'w') as f:\n",
    "            roots = []\n",
    "            child = []\n",
    "\n",
    "            f.write('Graph Nodes:')\n",
    "            f.writelines('\\n')\n",
    "            node_list = list(G.nodes)\n",
    "            str_list = [''.join(map(str,[\"X\",i, \": \"])) for i in node_list]\n",
    "\n",
    "            for i in range(len(node_list)):\n",
    "                if len(nx.ancestors(G, i)) ==0:\n",
    "                    roots.append(node_list[i])\n",
    "                    if (type_node[i] == 0):\n",
    "                        str_list[i] = ''.join(map(str,[\"X\",i, \": \",'N(', E_mean_con[i] ,',',E_var_con[i],\")\"]))\n",
    "                    else: \n",
    "                        str_list[i] = ''.join(map(str,[\"X\",i, \": \", 'Dis( U(0,1), 1, 1, 1, 1)']))\n",
    "                else: \n",
    "                    child.append(node_list[i])\n",
    "\n",
    "            while len(roots) < len(node_list): \n",
    "                node_list = np.array(list(G.nodes))\n",
    "                dis_nodes = node_list[type_node==1]\n",
    "                con_nodes = node_list[type_node==0]\n",
    "                for c in child:\n",
    "                    node_idx = np.argwhere(node_list==c)[0][0]\n",
    "                    # continuous child node\n",
    "                    if len(np.setdiff1d(list(nx.ancestors(G, c)),roots))==0 and type_node[node_idx] == 0:\n",
    "                        parent_idx = [pred for pred in G.predecessors(c)]\n",
    "                        parent_idx_dis = np.intersect1d(dis_nodes,parent_idx) # discrete parent node\n",
    "                        parent_idx_con = np.intersect1d(parent_idx,con_nodes) # continuous parent node\n",
    "\n",
    "                        # continuous par + Gaussian noise\n",
    "                        if len(parent_idx_con)>0:\n",
    "                            for con_idx in parent_idx_con:\n",
    "                                str_list[c] = ''.join(map(str,[str_list[c],  'X', con_idx, ' @ ' , theta_cc[con_idx,node_idx] , ' + '  ]))\n",
    "\n",
    "                        if len(parent_idx_dis)>0:\n",
    "                            for dis_idx in parent_idx_dis:\n",
    "                                str_list[c] = ''.join(map(str,[str_list[c],  'Switch(','X', dis_idx, theta_dc[dis_idx,node_idx].flatten() , ')' , ' + '  ]))\n",
    "                        str_list[c] = ''.join(map(str,[str_list[c], 'N(0,',E_var_con[node_idx] ,')']))\n",
    "                        child.remove(c);roots.append(c)\n",
    "\n",
    "                    if len(np.setdiff1d(list(nx.ancestors(G, c)),roots))==0 and type_node[node_idx] == 1:\n",
    "                        parent_idx = [pred for pred in G.predecessors(c)]\n",
    "                        parent_idx_dis = np.intersect1d(dis_nodes,parent_idx) # discrete parent node\n",
    "                        parent_idx_con = np.intersect1d(parent_idx,con_nodes) # continuous parent node\n",
    "                        str_list[c] = ''.join(map(str,[str_list[c], 'Dis( U(0,1), ']))\n",
    "\n",
    "                        dis_string  = ['','','','']\n",
    "                        if len(parent_idx_con)>0:\n",
    "                            for con_idx in parent_idx_con:\n",
    "                                for T in range(4):\n",
    "                                    dis_string[T] =  ''.join(map(str,[dis_string[T],  'X', con_idx, ' @ ' , theta_dc[[con_idx],node_idx,].flatten()[T] , ' + '  ]))\n",
    "\n",
    "                        if len(parent_idx_dis)>0:\n",
    "                            for dis_idx in parent_idx_dis:\n",
    "                                for T in range(4):\n",
    "                                    dis_string[T] =  ''.join(map(str,[dis_string[T],  'Switch(','X' ,dis_idx, theta_dd[dis_idx,node_idx][T],  ' + '  ]))\n",
    "\n",
    "                        dis_string = [i[:(len(i)-2)] for i in dis_string]\n",
    "                        dis_string = ', '.join(dis_string)\n",
    "                        str_list[c] = ''.join(map(str,[str_list[c], dis_string,  ')']))\n",
    "                        child.remove(c);roots.append(c)\n",
    "            for i in range(len(str_list)):\n",
    "                f.write(str_list[i])\n",
    "                f.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./Simulation_test/Dataset_75_05\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    G = random_dag(75,75) # generate dag with number of nodes and edges\n",
    "    n = 1000 # sample number\n",
    "    ratio_dis = 0.33 # discrete variable ratio\n",
    "    edge_precentage = 0.05 # precentage of edge deleted & added\n",
    "    num_edges = int(len(list(G.edges))*edge_precentage+0.4)\n",
    "    \n",
    "    \n",
    "    G_1 = G.copy()\n",
    "    G_2 = G.copy()\n",
    "    G_3 = G.copy()\n",
    "\n",
    "\n",
    "\n",
    "    G_1 = remove_DAG_edges(G_1,num_edges)\n",
    "    G_1 = add_DAG_edges(G_1,num_edges)\n",
    "\n",
    "    G_2 = remove_DAG_edges(G_2,num_edges)\n",
    "    G_2 = add_DAG_edges(G_2,num_edges)\n",
    "\n",
    "    G_3 = remove_DAG_edges(G_3,num_edges)\n",
    "    G_3 = add_DAG_edges(G_3,num_edges)\n",
    "\n",
    "\n",
    "\n",
    "    type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc = generate_parameters(G,ratio_dis)\n",
    "    X = simulate_data(G,n,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    df_x = array2DF(X)\n",
    "\n",
    "    X1 = simulate_data(G_1,n,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    df_x1 = array2DF(X1)\n",
    "    X2 = simulate_data(G_2,n,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    df_x2 = array2DF(X2)\n",
    "    X3 = simulate_data(G_3,n,type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    df_x3 = array2DF(X3)\n",
    "    \n",
    "    os.makedirs(''.join(['./Data',str(i)]),exist_ok=True)\n",
    "    os.makedirs(''.join(['./Data',str(i),'/data']),exist_ok=True)\n",
    "    df_x.to_csv(''.join(['./Data',str(i),'/data/data0.txt']), header=True, index=False, sep='\\t', mode='w')\n",
    "    df_x1.to_csv(''.join(['./Data',str(i),'/data/data1.txt']), header=True, index=False, sep='\\t', mode='w')\n",
    "    df_x2.to_csv(''.join(['./Data',str(i),'/data/data2.txt']), header=True, index=False, sep='\\t', mode='w')\n",
    "    df_x3.to_csv(''.join(['./Data',str(i),'/data/data3.txt']), header=True, index=False, sep='\\t', mode='w')\n",
    "\n",
    "    os.makedirs(''.join(['./Data',str(i),'/graph']),exist_ok=True)\n",
    "    \n",
    "    write_graph(G,''.join(['./Data',str(i),'/graph/graph0.txt']))\n",
    "    write_graph(G_1,''.join(['./Data',str(i),'/graph/graph1.txt']))\n",
    "    write_graph(G_2,''.join(['./Data',str(i),'/graph/graph2.txt']))\n",
    "    write_graph(G_3,''.join(['./Data',str(i),'/graph/graph3.txt']))\n",
    "    \n",
    "    write_parameter(G,''.join(['./Data',str(i),'/graph/parameter0.txt']),type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    write_parameter(G_1,''.join(['./Data',str(i),'/graph/parameter1.txt']),type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    write_parameter(G_2,''.join(['./Data',str(i),'/graph/parameter2.txt']),type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)\n",
    "    write_parameter(G_3,''.join(['./Data',str(i),'/graph/parameter3.txt']),type_node,E_mean_con,E_var_con,theta_cc,theta_dd,theta_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"font_size\": 20,\n",
    "    \"node_size\": 900,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 1,\n",
    "    \"width\": 2,\n",
    "    \"with_labels\":True,\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(24, 6))\n",
    "subax1 = plt.subplot(141)\n",
    "pos = nx.circular_layout(G) \n",
    "subax1.title.set_text('Reference Graph')\n",
    "nx.draw(G,pos=pos, **options)\n",
    "subax2 = plt.subplot(142)\n",
    "nx.draw(G_1,pos=pos, **options)\n",
    "subax2.title.set_text('Case 1')\n",
    "subax3 = plt.subplot(143)\n",
    "nx.draw(G_2,pos=pos, **options)\n",
    "subax3.title.set_text('Case 2')\n",
    "subax4 = plt.subplot(144)\n",
    "nx.draw(G_3,pos=pos, **options)\n",
    "subax4.title.set_text('Case 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "subax1 = plt.subplot(221)\n",
    "pos = nx.circular_layout(G) \n",
    "subax1.title.set_text('Reference Graph')\n",
    "nx.draw(G,pos=pos, **options)\n",
    "subax2 = plt.subplot(222)\n",
    "nx.draw(G_1,pos=pos, **options)\n",
    "subax2.title.set_text('Case 1')\n",
    "subax3 = plt.subplot(223)\n",
    "nx.draw(G_2,pos=pos, **options)\n",
    "subax3.title.set_text('Case 2')\n",
    "subax4 = plt.subplot(224)\n",
    "nx.draw(G_3,pos=pos, **options)\n",
    "subax4.title.set_text('Case 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydot\n",
    "from pycausal import search as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycausal.pycausal import pycausal as pc\n",
    "pc = pc()\n",
    "pc.start_vm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycausal import search as s\n",
    "tetrad = s.tetradrunner()\n",
    "tetrad.listScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetrad.getAlgorithmParameters(algoId = 'fges', scoreId = 'degen-gauss-bic')\n",
    "tetrad.run(algoId = 'fges', dfs = df_x, scoreId = 'degen-gauss-bic', \n",
    "           dataType = 'mixed', numCategoriesToDiscretize = 4, maxDegree = 4, faithfulnessAssumed = True, \n",
    "           symmetricFirstStep = True, verbose = False)\n",
    "print(len(tetrad.getEdges()))\n",
    "tetrad.getEdges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetrad.run(algoId = 'fges', dfs = df_x1, scoreId = 'degen-gauss-bic', \n",
    "           dataType = 'mixed', numCategoriesToDiscretize = 4, maxDegree = 4, faithfulnessAssumed = True, \n",
    "           symmetricFirstStep = True, verbose = False)\n",
    "print(len(tetrad.getEdges()))\n",
    "tetrad.getEdges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.stop_vm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycausal",
   "language": "python",
   "name": "pycausal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
